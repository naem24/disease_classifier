{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n",
      "Test is built with CUDA = False\n"
     ]
    }
   ],
   "source": [
    "# With only a train lot of 16K images and a batch size of 64, 20 epochs took 8 hours on a CPU with 16 GB\n",
    "# A GPU run took around 10 - 15 mins per epoch\n",
    "\n",
    "# Import key libraries\n",
    "import sys\n",
    "import os\n",
    "from os import makedirs, listdir\n",
    "import shutil\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from shutil import copyfile\n",
    "from random import random, seed\n",
    "\n",
    "# Load the necessary tensorflow and keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.utils as image\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Following code to optimise GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# Check to see if TF has GPU support and print the GPU device name\n",
    "if tf.test.gpu_device_name():\n",
    "   print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")\n",
    "\n",
    "print(\"Test is built with CUDA = \" + str(tf.test.is_built_with_cuda()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS FUNCTIONS\n",
    "\n",
    "# Preprocess images (renames them to 'other<n>' and 'xray<n>' and then resizes them to 224, 224 with a gray-scale)\n",
    "def OrganizeDataFromSource():\n",
    "    # A - Base folder creation and file copies\n",
    "    # If the proceessed folder is not there, create it\n",
    "    os.mkdir('data/tmp_processed')\n",
    "    os.mkdir('data/tmp_processed/others')\n",
    "    os.mkdir('data/tmp_processed/xrays')\n",
    "    \n",
    "    # getting all the files in the source directory\n",
    "    files = os.listdir('data/original_dataset/others')\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join('data/original_dataset/others', file), 'data/tmp_processed/others')\n",
    "    \n",
    "    # getting all the files in the source directory\n",
    "    files = os.listdir('data/original_dataset/xrays')\n",
    "    for index, file in enumerate(files):\n",
    "        shutil.copy(os.path.join('data/original_dataset/xrays', file), 'data/tmp_processed/xrays')\n",
    "    \n",
    "    print(\"File copies from source dataset to destination folders complete\")\n",
    "    \n",
    "    # B - Renames, grayscales and resizes\n",
    "    others_dest_path = \"data/tmp_processed/others\"\n",
    "    files = os.listdir(others_dest_path)\n",
    "\n",
    "    # With the sub-dirs made, copy image from source to dest\n",
    "    for index, file in enumerate(files):\n",
    "        if os.path.isfile(os.path.join(others_dest_path, ''.join(['other_',str(index+1), '.jpg']))):\n",
    "           break; \n",
    "        os.rename(os.path.join(others_dest_path, file), os.path.join(others_dest_path, ''.join(['other_',str(index+1), '.jpg']))) \n",
    "    \n",
    "    print(\"Renaming for 'others' complete\")\n",
    "    \n",
    "    for index, file in enumerate(files):\n",
    "        # Now resize the image and conver to grayscale\n",
    "        full_path = os.path.join(others_dest_path, ''.join(['other_',str(index+1), '.jpg']))\n",
    "        im_resized = image.load_img(full_path, target_size = (224,224), color_mode = 'grayscale')\n",
    "        img_array = image.img_to_array(im_resized)\n",
    "        image.save_img(full_path, img_array)\n",
    "    \n",
    "    print(\"Size and grayscale for 'others' complete\")\n",
    "    \n",
    "    xray_dest_path = \"data/tmp_processed/xrays\"\n",
    "    files = os.listdir(xray_dest_path)\n",
    "\n",
    "    # With the sub-dirs made, copy image from source to dest\n",
    "    for index, file in enumerate(files):\n",
    "        if os.path.isfile(os.path.join(xray_dest_path, ''.join(['xray_',str(index+1), '.jpg']))):\n",
    "            break;\n",
    "        os.rename(os.path.join(xray_dest_path, file), os.path.join(xray_dest_path, ''.join(['xray_',str(index+1), '.jpg'])))   \n",
    "    \n",
    "    print(\"Renaming for 'xrays' complete\")\n",
    "    \n",
    "    for index, file in enumerate(files):\n",
    "        # Now resize the image and conver to grayscale\n",
    "        full_path = os.path.join(xray_dest_path, ''.join(['xray_',str(index+1), '.jpg']))\n",
    "        im_resized = image.load_img(full_path, target_size = (224,224), color_mode = 'grayscale')\n",
    "        img_array = image.img_to_array(im_resized)\n",
    "        image.save_img(full_path, img_array)\n",
    "\n",
    "    print(\"Size and grayscale for 'xrays' complete\")\n",
    "\n",
    "    # C - Copy files across both the classes to a common directory for training as well as deriving mean, std purpose\n",
    "    if os.path.isdir('data/all_train'):\n",
    "        shutil.rmtree('data/all_train')\n",
    "        print(\"Removed folder all_train\")\n",
    "    \n",
    "    os.mkdir('data/all_train')\n",
    "    \n",
    "    if os.path.isdir('data/dataset_others_vs_xrays'):\n",
    "        shutil.rmtree('data/dataset_others_vs_xrays')\n",
    "        print(\"Removed folder dataset_others_vs_xrays\")\n",
    "    \n",
    "    os.mkdir('data/dataset_others_vs_xrays')\n",
    "\n",
    "    # Create sub-directories under the above newly created directory\n",
    "    dataset_home = 'data/dataset_others_vs_xrays/'\n",
    "    subdirs = ['train/', 'test/']\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        # create label subdirectories\n",
    "        labeldirs = ['others/', 'xrays/']\n",
    "        for labldir in labeldirs:\n",
    "            newdir = dataset_home + subdir + labldir\n",
    "            makedirs(newdir, exist_ok=True)\n",
    "    \n",
    "    # Copy both the xray and other content into the all_train folder\n",
    "    files = os.listdir('data/tmp_processed/others')\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join('data/tmp_processed/others', file), 'data/all_train')\n",
    "    \n",
    "    # getting all the files in the source directory\n",
    "    files = os.listdir('data/tmp_processed/xrays')\n",
    "    for index, file in enumerate(files):\n",
    "        shutil.copy(os.path.join('data/tmp_processed/xrays', file), 'data/all_train')\n",
    "\n",
    "    print(\"Copy of all processed files into all_train folder complete\")\n",
    "\n",
    "    # D - Create train / test folders in the ratio of 75:25 for both classes from the processed common folder created earlier\n",
    "    seed(1)\n",
    "\n",
    "    # define ratio of pictures to use for validation\n",
    "    val_ratio = 0.25\n",
    "\n",
    "    # copy training dataset images into subdirectories\n",
    "    src_directory = 'data/all_train/'\n",
    "\n",
    "    for file in listdir(src_directory):\n",
    "        src = src_directory + '/' + file\n",
    "        \n",
    "        dst_dir = 'train/'\n",
    "        if random() < val_ratio:\n",
    "            dst_dir = 'test/'\n",
    "            \n",
    "        if file.startswith('other'):\n",
    "            dst = dataset_home + dst_dir + 'others/'  + file\n",
    "            copyfile(src, dst)\n",
    "        elif file.startswith('xray'):\n",
    "            dst = dataset_home + dst_dir + 'xrays/'  + file\n",
    "            copyfile(src, dst)\n",
    "\n",
    "    # Finally, remove the temp folder\n",
    "    if os.path.isdir('data/tmp_processed'):\n",
    "        shutil.rmtree('data/tmp_processed')\n",
    "        print(\"Removed temp folder\")\n",
    "        \n",
    "    print(\"Creation of final dataset folders completed\")\n",
    "\n",
    "# Gets the mean across a sample of 100 images for all the 3 channels (RGB) and std deviation. This is useful to apply normalization prior\n",
    "# to training the model and before making a prediction on a test image\n",
    "def get_mean_std_per_batch(df, H, W):\n",
    "    sample_data = []\n",
    "    IMAGE_DIR = 'data/all_train/'\n",
    "    \n",
    "    for idx, img in enumerate(df.sample(100)[\"Image\"].values):\n",
    "        path = IMAGE_DIR + img\n",
    "        sample_data.append(np.array(image.load_img(path, target_size=(H, W))))\n",
    "\n",
    "    mean1 = np.mean(sample_data[0])\n",
    "    mean2 = np.mean(sample_data[1])\n",
    "    mean3 = np.mean(sample_data[2])\n",
    "    std = np.std(sample_data[0])\n",
    "    \n",
    "    return mean1, mean2, mean3, std    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copies from source dataset to destination folders complete\n",
      "Renaming for 'others' complete\n",
      "Size and grayscale for 'others' complete\n",
      "Renaming for 'xrays' complete\n",
      "Size and grayscale for 'xrays' complete\n",
      "Copy of all processed files into all_train folder complete\n",
      "Removed temp folder\n",
      "Creation of final dataset folders completed\n"
     ]
    }
   ],
   "source": [
    "OrganizeDataFromSource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "None\n",
      "RGB\n",
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "dest_path = \"data/dataset_others_vs_xrays/train/xrays\"\n",
    "path = os.path.join(dest_path, 'xray_1.jpg')\n",
    "img = load_img(path)\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "None\n",
      "RGB\n",
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "dest_path = \"data/dataset_others_vs_xrays/train/others\"\n",
    "path = os.path.join(dest_path, 'other_2.jpg')\n",
    "img = load_img(path)\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed dataset_others_vs_xrays folder\n",
      "Creation of final dataset folders completed\n"
     ]
    }
   ],
   "source": [
    "# Call the ProcessOriginalDataset function first if not done so\n",
    "CreateTrainTestFoldersFromProcessedDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Model_Transfer_VGG_16():\n",
    "    # We can use the feature extraction part of the model and add a new classifier part of the model\n",
    "    # that is tailored to the dogs and cats dataset. Specifically, we can hold the weights of all of the \n",
    "    # convolutional layers fixed during training, and only train new fully connected layers that will learn \n",
    "    # to interpret the features extracted from the model and make a binary classification    \n",
    "    \n",
    "    # This can be achieved by loading the VGG-16 model, removing the fully connected layers from the\n",
    "    # output-end of the model, then adding the new fully connected layers to interpret the model output \n",
    "    # and make a prediction. The classifier part of the model can be removed automatically by\n",
    "    # setting the “include_top” argument to “False“, which also requires that the shape of the input also \n",
    "    # be specified for the model, in this case (224, 224, 3). This means that the loaded model ends\n",
    "    # at the last max pooling layer, after which we can manually add a Flatten layer\n",
    "    # and the new clasifier layers.\n",
    "    \n",
    "    # Load the VGG model\n",
    "    model = VGG16(include_top = False, input_shape=(224, 224, 3), weights='data/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    \n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    \n",
    "    # Create the new classifier layers\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    \n",
    "    # Create the new output layer\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "    # Define the complete  model now with the VGG inputs and the new classifier layers\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    # Compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # Plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # Plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # Save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.34044164540816\n",
      "170.01317362882654\n",
      "146.68295599489795\n",
      "70.01424932635871\n"
     ]
    }
   ],
   "source": [
    "# Get the mean and std for sample (100 records from entire proceessed batch\n",
    "df = pd.read_csv('data/train-common.csv')\n",
    "mean1, mean2, mean3, std = get_mean_std_per_batch(df, 224, 224)\n",
    "\n",
    "print(mean1)\n",
    "print (mean2)\n",
    "print (mean3)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness_vgg_transfer():\n",
    "    \n",
    "    # Define model\n",
    "    model = Define_Model_Transfer_VGG_16()\n",
    "    \n",
    "    # We can load the images progressively using the Keras ImageDataGenerator class and flow_from_directory() API\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    \n",
    "    # DO NOT USE A CUSTOM MEAN AND STD - SEE DESCRIPTION BELOW\n",
    "    # The VGG16 model was trained on a specific ImageNet challenge dataset. As such, it is configured to expected input images \n",
    "    # to have the shape 224×224 pixels. We will use this as the target size when loading photos from our dataset.\n",
    "    # The model also expects images to be centered. That is, to have the mean pixel values from each channel (red, green, and blue) as \n",
    "    # calculated on the ImageNet training dataset subtracted from the input. Keras provides a function to perform this preparation for \n",
    "    # individual photos via the preprocess_input() function. Nevertheless, we can achieve the same effect with the ImageDataGenerator \n",
    "    # by setting the “featurewise_center” argument to “True” and manually specifying the mean pixel values to use when centering as \n",
    "    # the mean values from the ImageNet training dataset: [123.68, 116.779, 103.939].\n",
    "    \n",
    "    # Get the mean and std from a sample batch\n",
    "    #df = pd.read_csv('data/train-common.csv')\n",
    "    #mean1, mean2, mean3, std = get_mean_std_per_batch(df, 224, 224)\n",
    "    #train_datagen.mean = [mean1, mean2, mean3]\n",
    "    #train_datagen.std = std\n",
    "\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    \n",
    "    # Prepare iterators\n",
    "    train_it = datagen.flow_from_directory('data/dataset_others_vs_xrays/train',\n",
    "        class_mode='binary', batch_size=32, target_size=(224, 224))\n",
    "    \n",
    "    # The following is commented as we are now running the final lot with all the files together\n",
    "    test_it = datagen.flow_from_directory('data/dataset_others_vs_xrays/test',\n",
    "        class_mode='binary', batch_size=32, target_size=(224, 224))\n",
    "    \n",
    "    # Fit model\n",
    "    # Define a basic early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "    \n",
    "    # FOR UAR\n",
    "    # Commented the below lines as the final run does not require validation\n",
    "    history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data = test_it, validation_steps = len(test_it), epochs=10, verbose=1, callbacks=[es])\n",
    "\n",
    "    # FOR PROD\n",
    "    #history = model.fit(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=1, callbacks=[es])\n",
    "\n",
    "    # FOR UAT\n",
    "    # Evaluate model - Comment it out in the final run\n",
    "    _, acc = model.evaluate(test_it, steps=len(test_it), verbose = 1)\n",
    "    \n",
    "    # Print the accuracy after the fit is complete. Comment it out in the final run\n",
    "    #print('> %.3f' % (acc * 100.0))\n",
    "    \n",
    "    # Save the model\n",
    "    model.save('saved_model/final_xray_classifier_model.h5')\n",
    "\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4475 images belonging to 2 classes.\n",
      "Found 1489 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 986s 7s/step - loss: 0.1587 - accuracy: 0.9897 - val_loss: 3.3756e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 1129s 8s/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 1.2837e-04 - val_accuracy: 1.0000\n",
      "Epoch 2: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\Python\\ai_apps\\xray_identifier\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 312s 7s/step - loss: 1.2837e-04 - accuracy: 1.0000\n",
      "> 100.000\n"
     ]
    }
   ],
   "source": [
    "#run_test_harness()\n",
    "run_test_harness_vgg_transfer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction section\n",
    "\n",
    "# Load and prepare the image\n",
    "def load_image(filename):\n",
    "    # Load the image with the same size as loaded in the training set\n",
    "    img = image.load_img(filename, target_size=(224, 224), grayscale=True)\n",
    "    \n",
    "    # Convert to array\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Reshape into a single sample with 3 channels\n",
    "    \n",
    "    #img = img.reshape(1, 224, 224, 3)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Center pixel data\n",
    "    #df = pd.read_csv('data/train-common.csv')\n",
    "    #mean1, mean2, mean3, std = get_mean_std_per_batch(df, 224, 224)\n",
    "    #img = img - [mean1, mean2, mean3]    \n",
    "    \n",
    "    img = img.astype('float32')\n",
    "    img = img - [123.68, 116.779, 103.939]\n",
    "    \n",
    "    return img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example(path):\n",
    "    # load the image\n",
    "    img = load_image(path)\n",
    "    \n",
    "    # load model\n",
    "    model = load_model('saved_model/final_xray_classifier_model.h5')\n",
    "    \n",
    "    # predict the class\n",
    "    result = model.predict(img)\n",
    "    \n",
    "    return(result[0].astype('int'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 267ms/step\n",
      "[0]\n",
      "The image selected is not an x-ray\n"
     ]
    }
   ],
   "source": [
    "# Entry point, run the example\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_1.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_105.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_1033.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_1531.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_1602.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_1746.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/others/other_2677.jpg'\n",
    "\n",
    "\n",
    "#path = 'data/test/DSC_.jpg'\n",
    "#path = 'data/test/Farida_Rupawalla_PAN_Card.jpg'\n",
    "#path = 'data/test/mccaffe subscription.jpg'\n",
    "#path = 'data/test/Naem_Profile_Photo_2.jpg'\n",
    "path = 'data/test/DSC_0899 copy.jpg'\n",
    "#path = 'data/test/DSC_0901 copy.jpg'\n",
    "#path = 'data/test/Screenshot 2023-12-12 161432.png'\n",
    "\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_15.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_19.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_114.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_115.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_198.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_201.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_2966.jpg'\n",
    "#path = 'data/dataset_others_vs_xrays/test/xrays/xray_2977.jpg'\n",
    "\n",
    "result = run_example(path)\n",
    "\n",
    "# If result is less than or equal to 0, then the image is not an xray image else it is\n",
    "print(result)\n",
    "\n",
    "if result <= 0:\n",
    "    print(\"The image selected is not an x-ray\")\n",
    "else:\n",
    "    print(\"The image selected is an x-ray\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xray_identifier",
   "language": "python",
   "name": "xray_identifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
